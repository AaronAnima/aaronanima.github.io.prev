<!-- <!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"> -->
<!DOCTYPE HTML>
<html lang="en">
<!-- saved from url=(0023)https://jonbarron.info/ -->
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>Mingdong Wu &nbsp | &nbsp 吴铭东</title>
  <meta name="viewport" content="“width=800”">
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <!-- <link href="./QingnanFan_files/css" rel="stylesheet" type="text/css"> -->
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	  <link rel="icon" type="image/png" href="imgs/icon.jpg">
  <style type="text/css">
    /* Color scheme stolen from Sergey Karayev */
    a {
    color: #1772d0;
    text-decoration:none;
    }
    a:focus, a:hover {
    color: #f09228;
    text-decoration:none;
    }
    body,td,th,tr,p,a {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px
    }
    strong {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px;
    }
    heading {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 22px;
    }
    papertitle {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px;
    font-weight: 700
    }
    name {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 32px;
    }
    .one
    {
    width: 160px;
    height: 160px;
    position: relative;
    }
    .two
    {
    width: 160px;
    height: 160px;
    position: absolute;
    transition: opacity .2s ease-in-out;
    -moz-transition: opacity .2s ease-in-out;
    -webkit-transition: opacity .2s ease-in-out;
    }
    .fade {
     transition: opacity .2s ease-in-out;
     -moz-transition: opacity .2s ease-in-out;
     -webkit-transition: opacity .2s ease-in-out;
    }
    span.highlight {
        background-color: #ffffd0;
    }
  </style>
  <!-- <link rel="icon" type="image/png" href="https://jonbarron.info/seal_icon.png"> -->
  <!-- <link rel="stylesheet" type="text/css" href="stylesheet.css"> -->
  <title>Mingdong Wu &nbsp | &nbsp 吴铭东</title>
  <script charset="utf-8" src="chrome-extension://jgphnjokjhjlcnnajmfjlacjnjkhleah/js/btype.js"></script></head>
  <body>
  <!-- table1: my profile -->
  <table width="1100" border="0" align="center" cellspacing="0" cellpadding="0">
    <tbody><tr>
    <td>
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tbody><tr>
        <td width="67%" valign="middle">

        <p align="center">
          <name>Mingdong Wu &nbsp | &nbsp 吴铭东</name>
        </p>

        <p>
          I have been a Ph.D. student since 2021 in the School of Computer Science at Peking University, advised by Prof. Hao Dong.

          I received my bachelor degree in 2021, from <a href="https://cfcs.pku.edu.cn/english/research/turingprogram/introduction1/index.htm">Turing Class</a> in <a href="http://english.pku.edu.cn/">Peking University</a>.
        </p>
        <p>
        	My research interest lies in robot learning, generative models, reinforcement learning and 3D perception problems.
        	I aim to build intelligent embodied agents that <b>automatically discover and perform tasks without human specification</b>.
        </p>

        <p align="center">
          <a href="mailto:wmingd@pku.edu.cn">Email</a> &nbsp/&nbsp
          <a href="https://scholar.google.com/citations?hl=en&user=MPfBNuIAAAAJ">Google Scholar</a>
        </p>
        </td>
        <td width="33%">
        <img src="./wmd_2023.jpg" width="170px">
        <!-- <a href="https://hits.seeyoufarm.com"><img src="https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Faaronanima.github.io&count_bg=%2379C83D&title_bg=%23555555&icon=&icon_color=%23E7E7E7&title=hits&edge_flat=false"/>
        </a> -->
        </td>
      </tr>
      </tbody></table>



      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tbody><tr>
          <h1>Publications</h1>
      </tr>
      </tbody></table>

  <!-- table2: papers -->
  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tbody>
      <!-- (???) 3D Arrangement -->

      <!-- (TPAMI) TarGF+ -->


      <!-- (???) Diffusion Affordance -->

      <!-- (???) MAS-GF -->
      
      <!-- (NeurIPS23) DualGF -->
      <!-- <tr onmouseout="portrait_stop()" onmouseover="portrait_start()">
        <td width="25%">
          <div class="one">
          <div class="two" id="portrait_image" style="opacity: 0;"><img src="./imgs/2023ICML-DualGF-min.png" width="220px"></div>
          <img src="./imgs/2023ICML-DualGF-min.png" width="220px">
          </div>
          <script type="text/javascript">
          function portrait_start() {
          document.getElementById('portrait_image').style.opacity = "1";
          }
          function portrait_stop() {
          document.getElementById('portrait_image').style.opacity = "0";
          }
          portrait_stop()
          </script>
        </td>
        <td valign="top" width="75%">
      <a href="https://arxiv.org/pdf/.pdf">
              <papertitle>DualGF: Example-based Planning via Dual Gradient Fields</papertitle>
      </a>
      <br>
      <strong>Mingdong Wu</strong>, 
      Fangwei Zhong, 
      Yulong Xia, 
      Yizhou Wang, 
      Hao Dong
      <br>
          <em>Arxiv</em>, 2023<br>
          <a href="https://arxiv.org/pdf/.pdf">paper link</a>
          /
          <a href="https://sites.google.com/view/-coming-soon/">project page</a>
          / 
          <a href="./bibs/comming_soon.bib">bibtex</a>
          <p></p>
        </td>
      </tr> -->
      
      <!-- (Siggraph Asia 23) GF Packing -->
      <tr onmouseout="portrait_stop()" onmouseover="portrait_start()">
        <td width="25%">
          <div class="one">
          <div class="two" id="portrait_image" style="opacity: 0;"><img src="./imgs/gf_packing.jpg" width="220px"></div>
          <img src="./imgs/gf_packing.jpg" width="220px">
          </div>
          <script type="text/javascript">
          function portrait_start() {
          document.getElementById('portrait_image').style.opacity = "1";
          }
          function portrait_stop() {
          document.getElementById('portrait_image').style.opacity = "0";
          }
          portrait_stop()
          </script>
        </td>
        <td valign="top" width="75%">
      <a href="https://arxiv.org/abs/xxxx">
              <papertitle>Learning Gradient Fields for Scalable and Generalizable Irregular Packing</papertitle>
      </a>
      <br>
      Tianyang Xue, <strong>Mingdong Wu*</strong>, Lin Lu, Haoxuan Wang, Hao Dong, Baoquan Chen
      <br>
          <em>Siggraph Asia</em>, 2023<br>
          <a href="https://arxiv.org/abs/xxxx">paper link</a>
          /
          <a href="https://sites.google.com/view/xxxx">project page</a>
          /
          <a href="https://github.com/xxxx">codes</a>
          / 
          <a href="./bibs/xxxx.bib">bibtex</a>
          <p></p>
          <p> 
          </p>
        </td>
      </tr>

      <!-- (BMVC23 Oral) Diffusion PartAssembly -->
      <tr onmouseout="portrait_stop()" onmouseover="portrait_start()">
        <td width="25%">
          <div class="one">
          <div class="two" id="portrait_image" style="opacity: 0;"><img src="./imgs/score_pa.jpg" width="220px"></div>
          <img src="./imgs/score_pa.jpg" width="220px">
          </div>
          <script type="text/javascript">
          function portrait_start() {
          document.getElementById('portrait_image').style.opacity = "1";
          }
          function portrait_stop() {
          document.getElementById('portrait_image').style.opacity = "0";
          }
          portrait_stop()
          </script>
        </td>
        <td valign="top" width="75%">
      <a href="https://arxiv.org/abs/2309.06038">
              <papertitle>GraspGF: Learning Score-based Grasping Primitive for Human-assisting Dexterous Grasping</papertitle>
      </a>
      <br>
      Junfeng Cheng, <strong>Mingdong Wu</strong>, Ruiyuan Zhang, Guanqi Zhan, Chao Wu, Hao Dong
      <br>
          <em>BMVC</em>, 2023 (Oral)<br>
          <a href="https://arxiv.org/abs/2309.06038">paper link</a>
          /
          <a href="https://sites.google.com/view/xxxx">project page</a>
          /
          <a href="https://github.com/xxxx">codes</a>
          / 
          <a href="./bibs/xxxx.bib">bibtex</a>
          <p></p>
          <p> 
          </p>
        </td>
      </tr>
      
      <!-- (NeurIPS23) GraspGF -->
      <tr onmouseout="portrait_stop()" onmouseover="portrait_start()">
        <td width="25%">
          <div class="one">
          <div class="two" id="portrait_image" style="opacity: 0;"><img src="./imgs/demand_nav.jpg" width="220px"></div>
          <img src="./imgs/demand_nav.jpg" width="220px">
          </div>
          <script type="text/javascript">
          function portrait_start() {
          document.getElementById('portrait_image').style.opacity = "1";
          }
          function portrait_stop() {
          document.getElementById('portrait_image').style.opacity = "0";
          }
          portrait_stop()
          </script>
        </td>
        <td valign="top" width="75%">
      <a href="https://arxiv.org/abs/2309.06038">
              <papertitle>GraspGF: Learning Score-based Grasping Primitive for Human-assisting Dexterous Grasping</papertitle>
      </a>
      <br>
      Tianhao Wu,<strong>Mingdong Wu*</strong>, Jiyao Zhang, Yunchong Gan, Hao Dong
      <br>
          <em>Arxiv</em>, 2023<br>
          <a href="https://arxiv.org/abs/2309.06038">paper link</a>
          /
          <a href="https://sites.google.com/view/xxxx">project page</a>
          /
          <a href="https://github.com/xxxx">codes</a>
          / 
          <a href="./bibs/xxxx.bib">bibtex</a>
          <p></p>
          <p> 
          </p>
        </td>
      </tr>
      
      
      <!-- (NeurIPS23) Human-demand Navigation -->
      <tr onmouseout="portrait_stop()" onmouseover="portrait_start()">
        <td width="25%">
          <div class="one">
          <div class="two" id="portrait_image" style="opacity: 0;"><img src="./imgs/demand_nav.jpg" width="220px"></div>
          <img src="./imgs/demand_nav.jpg" width="220px">
          </div>
          <script type="text/javascript">
          function portrait_start() {
          document.getElementById('portrait_image').style.opacity = "1";
          }
          function portrait_stop() {
          document.getElementById('portrait_image').style.opacity = "0";
          }
          portrait_stop()
          </script>
        </td>
        <td valign="top" width="75%">
      <a href="https://arxiv.org/abs/2309.08138">
              <papertitle>Find What You Want: Learning Demand-conditioned Object Attribute Space for Demand-driven Navigation</papertitle>
      </a>
      <br>
      Hongcheng Wang, Andy Guan Hong Chen, Xiaoqi Li, <strong>Mingdong Wu</strong>, Hao Dong
      <br>
          <em>Arxiv</em>, 2023<br>
          <a href="https://arxiv.org/abs/2309.08138">paper link</a>
          /
          <a href="https://sites.google.com/view/xxxx">project page</a>
          /
          <a href="https://github.com/xxxx">codes</a>
          / 
          <a href="./bibs/xxxx.bib">bibtex</a>
          <p></p>
          <p> 
            The First Demand-driven Navigation Paper.
          </p>
        </td>
      </tr>
      
      <!-- (NeurIPS23) GenPose -->
      <tr onmouseout="portrait_stop()" onmouseover="portrait_start()">
        <td width="25%">
          <div class="one">
          <div class="two" id="portrait_image" style="opacity: 0;"><img src="./imgs/GenPose_V2.gif" width="220px"></div>
          <img src="./imgs/GenPose_V2.gif" width="220px">
          </div>
          <script type="text/javascript">
          function portrait_start() {
          document.getElementById('portrait_image').style.opacity = "1";
          }
          function portrait_stop() {
          document.getElementById('portrait_image').style.opacity = "0";
          }
          portrait_stop()
          </script>
        </td>
        <td valign="top" width="75%">
      <a href="https://arxiv.org/pdf/2306.10531v1.pdf">
              <papertitle>GenPose: Generative Category-level Object Pose Estimation via Diffusion Models</papertitle>
      </a>
      <br>
      Jiyao Zhang*,
      <strong>Mingdong Wu*</strong>, 
      Hao Dong
      <br>
          <em>Arxiv</em>, 2023<br>
          <a href="https://arxiv.org/pdf/2306.10531v1.pdf">paper link</a>
          /
          <a href="https://sites.google.com/view/genpose">project page</a>
          /
          <a href="https://github.com/Jiyao06/GenPose">codes</a>
          / 
          <a href="./bibs/genpose.bib">bibtex</a>
          <p></p>
          <p> 
            We explore a pure generative approach to tackle the <b>multi-hypothesis issue</b> in 6D Category-level Object Pose Estimation. 
            The key idea is to generate pose candidates using a score-based diffusion model and <b>filter out outliers</b> using an energy-based diffusion model. 
            By aggregating the remaining candidates, we can obtain a robust and high-quality output pose.
          </p>
        </td>
      </tr>
      
      <!-- (RAL23) Visual-Audio -->
      <tr onmouseout="portrait_stop()" onmouseover="portrait_start()">
        <td width="25%">
          <div class="one">
          <div class="two" id="portrait_image" style="opacity: 0;"><img src="./imgs/2023RAL-Visual-Audio-Nav-min.png" width="220px"></div>
          <img src="./imgs/2023RAL-Visual-Audio-Nav-min.png" width="220px">
          </div>
          <script type="text/javascript">
          function portrait_start() {
          document.getElementById('portrait_image').style.opacity = "1";
          }
          function portrait_stop() {
          document.getElementById('portrait_image').style.opacity = "0";
          }
          portrait_stop()
          </script>
        </td>
        <td valign="top" width="75%">
      <a href="https://arxiv.org/pdf/2304.10773.pdf">
              <papertitle>Learning Semantic-Agnostic and Spatial-Aware Representation for Generalizable Visual-Audio Navigation</papertitle>
      </a>
      <br>
      Hongcheng Wang*, 
      Yuxuan Wang*, 
      Fangwei Zhong, 
      <strong>Mingdong Wu</strong>, 
      Jianwei Zhang, 
      Yizhou Wang, 
      Hao Dong
      <br>
          <em>RAL</em>, 2023 <br>
          <a href="https://arxiv.org/pdf/2304.10773.pdf">paper link</a>
          /
          <a href="https://sites.google.com/view/sasavan/">project page</a>
          /
          <a href="https://github.com/wwwwwyyyyyxxxxx/SA2GVAN">codes</a>
          / 
          <a href="./bibs/visual_audio.bib">bibtex</a>
          <p></p>
        </td>
      </tr>

      <!-- (CVPR23) GFPose -->
      <tr onmouseout="portrait_stop()" onmouseover="portrait_start()">
        <td width="25%">
          <div class="one">
          <div class="two" id="portrait_image" style="opacity: 0;"><img src="./imgs/gfpose.jpeg" width="220px"></div>
          <img src="./imgs/gfpose.jpeg" width="220px">
          </div>
          <script type="text/javascript">
          function portrait_start() {
          document.getElementById('portrait_image').style.opacity = "1";
          }
          function portrait_stop() {
          document.getElementById('portrait_image').style.opacity = "0";
          }
          portrait_stop()
          </script>
        </td>
        <td valign="top" width="75%">
      <a href="https://arxiv.org/abs/2212.08641">
              <papertitle>GFPose: Learning 3D Human Pose Prior with Gradient Fields</papertitle>
      </a>
      <br>
      Hai Ci,
      <strong>Mingdong Wu</strong>, 
      Wentao Zhu,
      Xiaoxuan Ma,
      Hao Dong,
      Fangwei Zhong,
      Yizhou Wang
      <br>
          <em>CVPR</em>, 2023 <br>
          <a href="https://arxiv.org/abs/2212.08641">paper link</a>
          /
          <a href="https://github.com/Embracing/GFPose">project page</a>
          /
          <a href="https://github.com/Jiyao06/GenPose">codes</a>
          / 
          <a href="./bibs/gfpose.bib">bibtex</a>
          <p></p>
          <p> 
            GFPose is a <b>unified 3D human pose prior</b> model that can be easily used for various applications, e.g., 3D human pose estimation, pose denoising and generation. 
            Our key idea is to estimate the gradient field (a.k.a, score) of the perturbed human pose. 
            We can leverage the gradient to adjust poses to be more plausible and feasible to a task specification. 
          </p>
        </td>
      </tr>

      <!-- (NeurIPS22) TarGF -->
      <tr onmouseout="portrait_stop()" onmouseover="portrait_start()">
        <td width="25%">
          <div class="one">
          <div class="two" id="portrait_image" style="opacity: 0;"><img src="./imgs/targf_update.gif" width="220px"></div>
          <img src="./imgs/targf_update.gif" width="220px">
          </div>
          <script type="text/javascript">
          function portrait_start() {
          document.getElementById('portrait_image').style.opacity = "1";
          }
          function portrait_stop() {
          document.getElementById('portrait_image').style.opacity = "0";
          }
          portrait_stop()
          </script>
        </td>
        <td valign="top" width="75%">
      <a href="https://arxiv.org/abs/2209.00853">
              <papertitle>TarGF: Learning Target Gradient Field for Object Rearrangement</papertitle>
      </a>
      <br>
      <strong>Mingdong Wu*</strong>, 
      Fangwei Zhong*,
      <!-- <a href="https://fangweizhong.xyz/">Fangwei Zhong</a>,  -->
      Yulong Xia,
      <!-- <a href="https://zsdonghao.github.io/">Hao Dong</a>. -->
      Hao Dong.
      <br>
          <em>NeurIPS</em>, 2022 <br>
          <a href="https://arxiv.org/abs/2209.00853">paper link</a>
          /
          <a href="https://sites.google.com/view/targf">project page</a>
          /
          <a href="https://github.com/AaronAnima/TarGF">codes</a>
          / 
          <a href="./bibs/targf.bib">bibtex</a>
          <p></p>
          <p> 
            We study object rearrangement <b>without explicit goal specification</b>.
            The agent is given examples from a target distribution and aims at rearranging objects to increase the likelihood of the distribution.
            Our key idea is to learn a target gradient field that indicates the fastest direction to increase the likelihood from examples via score-matching.
          </p>
        </td>
      </tr>

   

  <!-- </tbody></table>
  <br href="https://hits.seeyoufarm.com">
    <img src="https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Faaronanima.github.io&count_bg=%2379C83D&title_bg=%23555555&icon=&icon_color=%23E7E7E7&title=visits&edge_flat=false"/>
  </br> -->



</body>

</html>